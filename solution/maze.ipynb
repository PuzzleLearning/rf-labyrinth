{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "262c14c3-eb2b-4e9e-b9e1-f4649fd3b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "720bce29-c0c5-499d-9c8b-ea5dd4a2b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba168d90-becb-4f7e-bde6-ce23d8a33eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labyrinth\n",
    "labyrinth = np.array([\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb470fda-d585-4c36-b3ea-dd00896bce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the possible actions\n",
    "actions = [\"up\", \"down\", \"left\", \"right\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6056f174-4b04-4779-824c-d8cabf2ff09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Q-table\n",
    "q_table = np.zeros((labyrinth.shape[0], labyrinth.shape[1], len(actions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c11556de-8377-482d-89cb-ce0d8b6beaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rate\n",
    "alpha = 0.8\n",
    "\n",
    "# Define the discount factor\n",
    "gamma = 0.95\n",
    "\n",
    "# Define the exploration rate\n",
    "epsilon = 0.1\n",
    "\n",
    "# Define the maximum number of episodes\n",
    "episodes = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8382ef33-3b81-4028-acd7-77c16d6b9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Q-learning algorithm\n",
    "for episode in tqdm(range(episodes)):\n",
    "    # Set the initial state\n",
    "    state = (0, 0)\n",
    "\n",
    "    # Loop until the agent reaches the goal\n",
    "    while (abs(state[0]) < len(labyrinth[0])) and (abs(state[1]) < len(labyrinth[1])):\n",
    "        # Select the action with the highest Q-value\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "            action = np.random.choice(actions)\n",
    "        else:\n",
    "            action = actions[np.argmax(q_table[state[0], state[1]])]\n",
    "\n",
    "        # Take the action and observe the new state and reward\n",
    "        if action == \"up\":\n",
    "            new_state = (state[0] - 1, state[1])\n",
    "            reward = -1 if labyrinth[new_state[0], new_state[1]] == 1 else 0\n",
    "        elif action == \"down\":\n",
    "            new_state = (state[0] + 1, state[1])\n",
    "            reward = -1 if labyrinth[new_state[0], new_state[1]] == 1 else 0\n",
    "        elif action == \"left\":\n",
    "            new_state = (state[0], state[1] - 1)\n",
    "            reward = -1 if labyrinth[new_state[0], new_state[1]] == 1 else 0\n",
    "        elif action == \"right\":\n",
    "            new_state = (state[0], state[1] + 1)\n",
    "            reward = -1 if labyrinth[new_state[0], new_state[1]] == 1 else 0\n",
    "\n",
    "        # Update the Q-value\n",
    "        q_table[state[0], state[1], actions.index(action)] = q_table[state[0], \n",
    "                                                                     state[1], \n",
    "                                                                     actions.index(action)] + alpha * (reward + gamma * np.max(q_table[new_state[0], new_state[1]]) - q_table[state[0], state[1], actions.index(action)])\n",
    "\n",
    "        # Update the state\n",
    "        state = new_state\n",
    "\n",
    "        # Check if the goal is reached\n",
    "        if state == (labyrinth.shape[0] - 1, labyrinth.shape[1] - 1):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc91c61f-f13d-4147-80dd-29db3f96a333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fdd4ed9e-3366-4f26-ac69-fc3f43e3608a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        , -1.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        , -1.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , -1.        ],\n",
       "        [ 0.        , -0.99999949,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.999936  , -0.99999744],\n",
       "        [ 0.        , -0.992     ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -1.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , -1.        ],\n",
       "        [-0.9999872 , -0.99968   ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.9984    , -0.99999998],\n",
       "        [-0.8       , -0.96      ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -1.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , -1.        ],\n",
       "        [-0.99999998,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -1.        , -1.        ],\n",
       "        [-0.992     ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -1.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-1.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-1.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the Q-table\n",
    "q_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
